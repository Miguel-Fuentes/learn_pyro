{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI Part 1: An introduction to Stochastic Variational Inference\n",
    "This is taken from [this](https://pyro.ai/examples/svi_part_i.html) page from the pyro examples section\n",
    "Miguel Fuentes\n",
    "Created: 4/29/2020\n",
    "Last Updated: 4/30/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import pyro.distributions as dist\n",
    "\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We can perform SVI on more or less arbitrary stochastic functions with Pyro. Besides the inputs the main components of a pyro model are as follows:\n",
    "1) Observations (included with pyro.sample using obs keyword)  \n",
    "2) Latent variables (included with pyro.sample)  \n",
    "3) Paramaters (included with pyro.param)   \n",
    "\n",
    "Every set of paramaters defines a joint probability over the observations and the latent variables. To perform SVI we need these assumptions about the joint pdfs defined by the paramaters:  \n",
    "- We can sample from the pdfs\n",
    "- We can compute the pointwise log pdf at any point\n",
    "- The pdf is differentiable w.r.t. the paramaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What exactly are we trying to learn?\n",
    "We want to find the most likely paramaters for our model, this can be rewritten as \n",
    "$$\\theta_{max} = \\underset{\\theta}{\\text{argmax}} log(p_{\\theta}(x))$$  \n",
    "To compute this quantity we must integrate over the latent variables. Doing this is often intractible, and even if we can do it we usually end up with a really hard non-convex optimization problem.  \n",
    "Additionally, we also want to compute posteriors for the latent variables once we have the most likely paramaters. This requires another challenging computation:  \n",
    "$$p_{\\theta_{max}}(z|x) = \\frac{p_{\\theta_{max}}(x,z)}{\\int d\\textbf{z}p_{\\theta_{max}}(x,z)}$$  \n",
    "We don't want to, of often can't, do these calculations so we need a better way. Variational inference gives us a scheme to calculate $\\theta_{max}$ and getting an approximate estimate for $p_{\\theta_{max}}(z|x)$ . For this we need a few things, one of the most important is a guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide\n",
    "The idea here is to introduce a family of distributions paramaterizes by $\\phi$, $q_{\\phi}(z)$ over the latent variables. We will search this distribution space and try to find the best possible approximation of $p_{\\theta_{max}}(z|x)$. In the literature qe call $\\phi$ the variational paramaters and we call $q_{\\phi}(z)$ the variational distribution. In pyro, this is called the guide because that is shorter and easier to remember.  \n",
    "We will define our guide function the same way we would define any other model in pyro. However, ince we need the guide to produce a joint distribution over the latent variables, we need to impose some constraints:  \n",
    "1) The model and guide should have the same call signature (args and kwargs)  \n",
    "2) The guide should not include any observations  \n",
    "3) Any latent variable which is appears in the model (with a pyro.sample call) must also appear in the guide  \n",
    "Once we have defined the guide we can go on to search the distribution space for the best posterior approximation. To do this we need an objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELBO\n",
    "The ELBO (evidence lower bound) is the objective function we are going to optimize. The reason we choose to optimize this is that we know that maximizing the ELBO will result in minimizing the KL divergence between $q_{\\phi}(z)$ and $p_{\\theta}(z|x)$ and this is exactly the goal of Variational Inference. Maximizing ELBO minimizes KL divergence as a result of this identity:  \n",
    "$$logp_{\\theta}(x) − ELBO =KL(q_{\\phi}(z)||p_{\\theta}(z|x))$$  \n",
    "For a fixed θ, as we take steps in ϕ space that increase the ELBO, we decrease the KL divergence between the guide and the posterior, i.e. we move the guide towards the posterior. In the general case we take gradient steps in both θ and ϕ space simultaneously so that the guide and model play chase, with the guide tracking a moving posterior $logp_{\\theta}(z|x)$. Perhaps somewhat surprisingly, despite the moving target, this optimization problem can be solved (to a suitable level of approximation) for many different problems.  \n",
    "So at high level variational inference is easy: all we need to do is define a guide and compute gradients of the ELBO. Actually, computing gradients for general model and guide pairs leads to some complications (see the tutorial SVI Part III for a discussion). For the purposes of this tutorial, let’s consider that a solved problem and look at the support that Pyro provides for doing variational inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVI Class\n",
    "In Pyro the machinery for doing variational inference is encapsulated in the SVI class.\n",
    "The user needs to provide three things: the model, the guide, and an optimizer. We’ve discussed the model and guide above and we’ll discuss the optimizer in some detail below, so let’s assume we have all three ingredients at hand.  \n",
    "The SVI object provides two methods, step() and evaluate_loss(), that encapsulate the logic for variational learning and evaluation:  \n",
    " - The method step() takes a single gradient step and returns an estimate of the loss (i.e. minus the ELBO). If provided, the arguments to step() are piped to model() and guide().  \n",
    " - The method evaluate_loss() returns an estimate of the loss without taking a gradient step. Just like for step(), if provided, arguments to evaluate_loss() are piped to model() and guide().  \n",
    "For the case where the loss is the ELBO, both methods also accept an optional argument num_particles, which denotes the number of samples used to compute the loss (in the case of evaluate_loss) and the loss and gradient (in the case of step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "In Pyro, the model and guide are allowed to be arbitrary stochastic functions provided that:  \n",
    " - guide doesn’t contain pyro.sample statements with the obs argument  \n",
    " - model and guide have the same call signature  \n",
    "\n",
    "This presents some challenges because it means that different executions of model() and guide() may have quite different behavior, with e.g. certain latent random variables and parameters only appearing some of the time. Indeed parameters may be created dynamically during the course of inference. In other words the space we’re doing optimization over, which is parameterized by θ and ϕ, can grow and change dynamically.  \n",
    "In order to support this behavior, Pyro needs to dynamically generate an optimizer for each parameter the first time it appears during learning. Luckily, PyTorch has a lightweight optimization library (see torch.optim) that can easily be repurposed for the dynamic case.  \n",
    "All of this is controlled by the optim.PyroOptim class, which is basically a thin wrapper around PyTorch optimizers. PyroOptim takes two arguments: a constructor for PyTorch optimizers optim_constructor and a specification of the optimizer arguments optim_args. At high level, in the course of optimization, whenever a new parameter is seen optim_constructor is used to instantiate a new optimizer of the given type with arguments given by optim_args.  \n",
    "\n",
    "Most users will probably not interact with PyroOptim directly and will instead interact with the aliases defined in optim/__init__.py. There are two ways to specify the optimizer arguments. In the simpler case, optim_args is a fixed dictionary that specifies the arguments used to instantiate PyTorch optimizers for all the parameters.  \n",
    "The second way to specify the arguments allows for a finer level of control. Here the user must specify a callable that will be invoked by Pyro upon creation of an optimizer for a newly seen parameter. This callable must have the following signature:  \n",
    " - module_name: the Pyro name of the module containing the parameter, if any\n",
    " - param_name: the Pyro name of the parameter  \n",
    "This gives the user the ability to, for example, customize learning rates for different parameters. For an example where this sort of level of control is useful, see the discussion of baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Determing Coin Fairness\n",
    "For a simple example we'll assume you are given a coin, you want to determine what the probability that the coin will land on heads is. You have a prior distribution over the fairness defined by Beta(10, 10), then you observe some data and want to update the belief about the coin fairness based on the data. First, we generate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some data with 6 observed heads and 4 observed tails\n",
    "data = []\n",
    "for _ in range(6):\n",
    "    data.append(torch.tensor(1.0))\n",
    "for _ in range(4):\n",
    "    data.append(torch.tensor(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to model the coin flips based on our prior belief and make observations on the data. We will also define our guide now. Notice the following things about the guide and the model:  \n",
    " - We’ve taken care that the names of the random variables line up exactly between the model and guide.\n",
    " - model(data) and guide(data) take the same arguments.\n",
    " - The variational parameters are torch.tensors. The requires_grad flag is automatically set to True by pyro.param.\n",
    " - We use constraint=constraints.positive to ensure that alpha_q and beta_q remain non-negative during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the param store in case we're in a REPL\n",
    "pyro.clear_param_store()\n",
    "\n",
    "def model(data):\n",
    "    # define the hyperparameters that control the beta prior\n",
    "    alpha0 = torch.tensor(10.0)\n",
    "    beta0 = torch.tensor(10.0)\n",
    "    # sample f from the beta prior\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    # loop over the observed data\n",
    "    for i in range(len(data)):\n",
    "        # observe datapoint i using the bernoulli likelihood\n",
    "        pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])\n",
    "\n",
    "def guide(data):\n",
    "    # register the two variational parameters with Pyro\n",
    "    # - both parameters will have initial value 15.0.\n",
    "    # - because we invoke constraints.positive, the optimizer\n",
    "    # will take gradients on the unconstrained parameters\n",
    "    # (which are related to the constrained parameters by a log)\n",
    "    alpha_q = pyro.param(\"alpha_q\", torch.tensor(15.0),\n",
    "                         constraint=constraints.positive)\n",
    "    beta_q = pyro.param(\"beta_q\", torch.tensor(15.0),\n",
    "                        constraint=constraints.positive)\n",
    "    # sample latent_fairness from the distribution Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform the inference. Note that in the step() method we pass in the data, which then get passed to the model and guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:05<00:00, 297.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "based on the data and our prior belief, the fairness of the coin is 0.535 +- 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# setup the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 1500\n",
    "# do gradient steps\n",
    "for step in tqdm(range(n_steps)):\n",
    "    svi.step(data)\n",
    "\n",
    "# grab the learned variational parameters\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "\n",
    "# here we use some facts about the beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "\n",
    "print(\"\\nbased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This estimate is to be compared to the exact posterior mean, which in this case is given by 16/30=0.53. Note that the final estimate of the fairness of the coin is in between the the fairness preferred by the prior (namely 0.50) and the fairness suggested by the raw empirical frequencies (6/10=0.60)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
